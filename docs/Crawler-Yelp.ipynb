{
 "metadata": {
  "name": "",
  "signature": "sha256:61211267facce6379e59b585eae86b232f1e6fa9d5265321b2bd1f5541783c1a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Crawler: Yelp"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Author: Kelly Chan | Date: July 14 2014"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Description"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "- website: [Yelp: http://www.yelp.com/la](http://www.yelp.com/la)\n",
      "- sub_url: http://www.yelp.com/search?find_desc=%s&find_loc=Los+Angeles&ns=1\n",
      "- %s: the name of a restaurant"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 1. URLs:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "| Restaurant                         |  Leaf Page                                                              |\n",
      "|:-----------------------------------|:------------------------------------------------------------------------|\n",
      "| Chego                              | http://www.yelp.com//biz/chego-los-angeles-5                            |\n",
      "| Smitty\u2019s Famous Fish and Chicken   | http://www.yelp.com//biz/smittys-famous-fish-and-chicken-culver-city    |\n",
      "| Zankou Chicken                     | http://www.yelp.com//biz/zankou-chicken-los-angeles-2                   |\n",
      "| Ambala Dhaba                       | http://www.yelp.com//biz/ambala-dhaba-artesia-2                         |\n",
      "| Fuddruckers (on Santa Monica Blvd) | http://www.yelp.com//biz/fuddruckers-burbank                            |\n",
      "| Colony Cafe                        | http://www.yelp.com//biz/the-colony-cafe-los-angeles                    |"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2. Regexes\n",
      "\n",
      "Please note that the regexes shown below are used to parse the data from the target html contents."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "| No.   | Attribute                  |  Regex (Python)                                                         |\n",
      "|:------|:---------------------------|:------------------------------------------------------------------------|\n",
      "| 01    | index                      | r\"<span class=\\\"indexed-biz-name\\\">(\\d+)\"                               |\n",
      "| 02    | link                       | r\"biz-name\\\".*(/biz/[\\w?%?+-?]+)\\\"\"                                     |\n",
      "| 03    | name                       | r\"biz-name.*>(<.*>.*|\\w+\\s+<.*>.*)</a>\"                                 |\n",
      "| 04    | rating                     | r\"star-img ([\\w+_?]+)\"                                                  |\n",
      "| 05    | review                     | r\"(\\d+) reviews\"                                                        |\n",
      "| 06    | price                      | r\"business-attribute price-range\\\">(.*)</span>\"                         |\n",
      "| 07    | category                   | r\"cflt=(\\w+)\"                                                           |\n",
      "| 08    | neighborhood               | r\"neighborhood-str-list\\\">\\n\\s+(.*)\\s+</span>\"                          |\n",
      "| 09    | address                    | r\"<address>\\n([\\s\\S]*)</address>\"                                       |\n",
      "| 10    | phone                      | r\"biz-phone\\\">\\n\\s+(.*)\\n\\s+</span>\"                                    |\n",
      "| 11    | feedback                   | r\"<p class=\\\"snippet\\\">(.*)</p>\"                                        |"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 3. Data\n",
      "\n",
      "full attributes after cleansing\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "| No.   | Attribute                  |  Attributes Splitted                                                    |\n",
      "|:------|:---------------------------|:------------------------------------------------------------------------|\n",
      "| 01    | index                      |                                                                         |\n",
      "| 02    | link                       |                                                                         |\n",
      "| 03    | name                       |                                                                         |\n",
      "| 04    | rating                     |                                                                         |\n",
      "| 05    | review                     |                                                                         |\n",
      "| 06    | price                      |                                                                         |\n",
      "| 07    | category                   | categories                                                              |\n",
      "| 08    | neighborhood               |                                                                         |\n",
      "| 09    | address                    | road, city, post code                                                   |\n",
      "| 10    | phone                      |                                                                         |\n",
      "| 11    | feedback                   |                                                                         |"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Source Codes\n",
      "\n",
      "- step1. extracting attributes from the html contents\n",
      "- step2. cleansing the data from the extracted attributes\n",
      "\n",
      "#### 1. Extracting atttributes from the html contents"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Author: Kelly Chan\n",
      "Date: July 14 2014\n",
      "\n",
      "Project: Extracting attributes from the html contents (Yelp)\n",
      "\n",
      "- url: http://www.yelp.com/search?find_desc=%s&find_loc=Los+Angeles&ns=1\n",
      "- %s: the name of a specific restaurant\n",
      "\n",
      "steps:\n",
      "- 1. getting the html contents\n",
      "- 2. parsing attributes by regexes\n",
      "- 3. saving the data(.txt) to the local drive\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "import re\n",
      "import time\n",
      "import urllib2\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "def getHTML(url):\n",
      "    \"\"\" return the html contents from the specific url \"\"\"\n",
      "\n",
      "    time.sleep(2.00)\n",
      "    html = urllib2.urlopen(url,timeout=10).read()\n",
      "    urllib2.urlopen(url).close()\n",
      "\n",
      "    soup = BeautifulSoup(html)\n",
      "\n",
      "    return soup\n",
      "\n",
      "\n",
      "def extractAttribute(content, pattern):\n",
      "    \"\"\" return the attribute that matching a specific pattern in the content \"\"\"\n",
      "    \n",
      "    return re.findall(re.compile(pattern), str(contents))\n",
      "\n",
      "def extract(soup, keyIndex):\n",
      "    \"\"\" return all attributes those matching specific patterns in the individual content \"\"\"\n",
      "\n",
      "    # getting the individual content\n",
      "    content = soup.find('div', attrs={'data-key': keyIndex})\n",
      "\n",
      "    # index\n",
      "    pattern = r\"<span class=\\\"indexed-biz-name\\\">(\\d+)\"\n",
      "    index = extractAttribute(content, pattern)\n",
      "    #print index\n",
      "\n",
      "    # link\n",
      "    pattern = r\"biz-name\\\".*(/biz/[\\w?%?+-?]+)\\\"\"\n",
      "    #pattern = r\"biz-name\\\".*(/biz/.*)\\\"\" \n",
      "    link = extractAttribute(content, pattern)\n",
      "    #print link\n",
      "\n",
      "    # name\n",
      "    #pattern = r\"biz-name.*>(.*)</a>\" \n",
      "    pattern = r\"biz-name.*>(<.*>.*|\\w+\\s+<.*>.*)</a>\"\n",
      "    name = extractAttribute(content, pattern) \n",
      "    #print name\n",
      "\n",
      "    # rating\n",
      "    pattern = r\"star-img ([\\w+_?]+)\"\n",
      "    rating = extractAttribute(content, pattern)\n",
      "    #print rating\n",
      "\n",
      "    # review\n",
      "    pattern = r\"(\\d+) reviews\"\n",
      "    review = extractAttribute(content, pattern)\n",
      "    #print review\n",
      "\n",
      "    # price\n",
      "    pattern = r\"business-attribute price-range\\\">(.*)</span>\"\n",
      "    price = extractAttribute(content, pattern)\n",
      "    #print price\n",
      "\n",
      "    # category\n",
      "    pattern = r\"cflt=(\\w+)\"\n",
      "    category = extractAttribute(content, pattern)\n",
      "    #print category\n",
      "\n",
      "    # neighborhood\n",
      "    pattern = r\"neighborhood-str-list\\\">\\n\\s+(.*)\\s+</span>\"\n",
      "    neighborhood = extractAttribute(content, pattern)\n",
      "    #print neighborhood\n",
      "\n",
      "    # address\n",
      "    #pattern = r\"\\s+(.*)<br>\"\n",
      "    pattern = r\"<address>\\n([\\s\\S]*)</address>\"\n",
      "    address = extractAttribute(content, pattern)\n",
      "    #print address\n",
      "\n",
      "    # phone\n",
      "    #pattern = r\"(\\([\\d]+\\) [\\d]+-[\\d]+)\"\n",
      "    pattern = r\"biz-phone\\\">\\n\\s+(.*)\\n\\s+</span>\"\n",
      "    phone = extractAttribute(content, pattern)\n",
      "    #print phone\n",
      "\n",
      "    # feedback\n",
      "    pattern = r\"<p class=\\\"snippet\\\">(.*)</p>\"\n",
      "    feedback = extractAttribute(content, pattern)\n",
      "    #print feedback\n",
      "\n",
      "    return [index, link, name, \\\n",
      "            rating, review, price, category, \\\n",
      "            neighborhood, address, phone, feedback]\n",
      "\n",
      "\n",
      "def outTxt(data, outPath, fileName):\n",
      "    \"\"\" outputing the data as txt file \"\"\"\n",
      "\n",
      "    with open(outPath+fileName, \"wb\") as f:\n",
      "        f.write(\"index,link,name,rating,review,price,category,neighborhood,address,phone,feedback\\n\")\n",
      "        for record in data:\n",
      "            f.write(\"%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s\\n\" % \\\n",
      "                    (record[0],record[1],record[2],record[3],record[4],record[5],record[6],\\\n",
      "                     record[7],record[8],record[9],record[10]))\n",
      "\n",
      "\n",
      "def getBizListData(url, bizList):\n",
      "    \"\"\" return the full data set by extracting attributes from the html contents one by one (bizList) \"\"\"\n",
      "\n",
      "    data = []\n",
      "    for restaurant in bizList:\n",
      "        pageURL = (url % restaurant.replace(\" \", \"+\"))\n",
      "        soup = getHTML(pageURL)\n",
      "\n",
      "        record = extract(soup, \"1\")\n",
      "        data.append(record)\n",
      "    \n",
      "    return data\n",
      "\n",
      "def main():\n",
      "\n",
      "    outPath = \"path/regexEval/data/\"\n",
      "    url = \"http://www.yelp.com/search?find_desc=%s&find_loc=Los+Angeles&ns=1\"\n",
      "    fileName = \"bizList_data.txt\"\n",
      "\n",
      "    bizList = ['Chego', \\\n",
      "               'Smitty\\'s Famous Fish and Chicken', \\\n",
      "               'Zankou Chicken', \\\n",
      "               'Ambala Dhaba', \\\n",
      "               'Fuddruckers', \\\n",
      "               'Colony Cafe']    \n",
      "    \n",
      "    data = getBizListData(url, bizList)\n",
      "    outTxt(data, outPath, fileName)\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2. Cleansing the data from the extracted attributes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Author: Kelly Chan\n",
      "Date: July 14 2014\n",
      "\n",
      "Project: Cleansing the data from the extracted attributes (BizList)\n",
      "\n",
      "- url: http://www.yelp.com/search?find_desc=%s&find_loc=Los+Angeles&ns=1\n",
      "- %s: the name of a specific restaurant\n",
      "\n",
      "steps:\n",
      "- 1. getting the data extracted from the html contents\n",
      "- 2. cleansing the data by attributes\n",
      "- 3. saving the cleaned data (.tsv) to the local drive\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "def getData(datafile):\n",
      "    \"\"\" return the data from the txt file \"\"\"\n",
      "\n",
      "    data = []\n",
      "    with open(datafile, 'rb') as f:\n",
      "        for line in f.readlines():\n",
      "            thisLine = line.strip().split('],[')\n",
      "            data.append(thisLine)\n",
      "    return data\n",
      "\n",
      "def cleanLeftBracket(attribute):\n",
      "    \"\"\" cleansing the left bracket out \"\"\"\n",
      "\n",
      "    return attribute.replace(\"['\", \"\").replace(\"'\", \"\")\n",
      "\n",
      "def cleanRightBracket(attribute):\n",
      "    \"\"\" cleansing the right bracket out \"\"\"\n",
      "    \n",
      "    return attribute.replace(\"]\", \"\")\n",
      "\n",
      "def cleanString(attribute):\n",
      "    \"\"\" cleaning the ' as empty \"\"\"\n",
      "    \n",
      "    return attribute.replace(\"'\", \"\")\n",
      "\n",
      "def cleanAttributes(data):\n",
      "    \"\"\" cleansing the attributes one by one and then return the cleaned data \"\"\"\n",
      "\n",
      "    cleanedData = []\n",
      "\n",
      "    for record in data[1:]:\n",
      "\n",
      "        # index\n",
      "        index = cleanLeftBracket(record[0]).strip()\n",
      "        #print index\n",
      "\n",
      "        # link\n",
      "        link = cleanString(record[1]).strip()\n",
      "        link = \"http://www.yelp.com/\" + link\n",
      "        #print link\n",
      "        \n",
      "        # name\n",
      "        name = cleanString(record[2]).strip()\n",
      "        name = name.replace(\"<span class=\\\"highlighted\\\">\", \"\")\n",
      "        name = name.replace(\"</span>\", \"\")\n",
      "        #print name\n",
      "\n",
      "        # rating\n",
      "        rating = cleanString(record[3]).strip()\n",
      "        #print rating\n",
      "\n",
      "        # review\n",
      "        review = cleanString(record[4]).strip()\n",
      "        #print review\n",
      "\n",
      "        # price\n",
      "        price = cleanString(record[5]).strip()\n",
      "        #print price\n",
      "\n",
      "        # category\n",
      "        categories = cleanString(record[6]).strip()\n",
      "        #print categories\n",
      "\n",
      "        # neighborhood\n",
      "        neighborhood = cleanString(record[7]).strip()\n",
      "        #print neighborhood\n",
      "\n",
      "        # address\n",
      "        address = cleanString(record[8]).strip()\n",
      "        address = address.replace(\"\\\\n        </br>\", \"\")\n",
      "        address = address.replace(\"\\\\n\", \"\")\n",
      "        address = address.split('<br>')\n",
      "        if len(address) == 1:\n",
      "            road = \"\"\n",
      "            mainAddress = address[0]\n",
      "        elif len(address) == 2:\n",
      "            road = address[0].strip()\n",
      "            mainAddress = address[1]\n",
      "        #print road\n",
      " \n",
      "        mainAddress = mainAddress.split(\",\")\n",
      "        city = mainAddress[0].strip()\n",
      "        state, postCode = mainAddress[1].strip().split(\" \")\n",
      "        #print city\n",
      "        #print state, postCode\n",
      "\n",
      "        # phone\n",
      "        phone = cleanString(record[9]).strip()\n",
      "        #print phone\n",
      "\n",
      "        # feedback\n",
      "        feedback = cleanRightBracket(record[10]) \n",
      "        #print feedback\n",
      "\n",
      "        cleanedData.append([index, link, name, rating, review, price, categories, \\\n",
      "                     neighborhood, road, city, postCode, phone, feedback])\n",
      "\n",
      "    return cleanedData\n",
      "\n",
      "def outTSV(data, outPath, fileName):\n",
      "    \"\"\" output the data as .tsv file \"\"\"\n",
      "\n",
      "    header = \"index\\tlink\\tname\\trating\\treview\\tprice\\tcategories\\tneighborhood\\troad\\tcity\\tpostcode\\tphone\\tfeedback\\n\"\n",
      "\n",
      "    with open(outPath+fileName, \"wb\") as f:\n",
      "        f.write(header)\n",
      "        for record in data:\n",
      "            f.write(\"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n\" % \\\n",
      "                    (record[0],record[1],record[2],record[3],record[4],record[5],record[6],\\\n",
      "                     record[7],record[8],record[9],record[10],record[11],record[12]))\n",
      "\n",
      "\n",
      "def main():\n",
      "\n",
      "    dataPath = \"path/regexEval/data/\"\n",
      "    fileName = \"bizList_data.txt\"\n",
      "    outName = \"cleaned_bizList_data.tsv\"\n",
      "\n",
      "    data = getData(dataPath+fileName)\n",
      "    cleanedData = cleanAttributes(data)\n",
      "    outTSV(cleanedData, dataPath, outName)\n",
      " \n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Additional Solution: Extracting the data by pages (crawler)\n",
      "\n",
      "- step1. extracting attributes from the html contents (by pages)\n",
      "- step2. cleansing the data from the extracted attributes\n",
      "\n",
      "#### 1. Extracting atttributes from the html contents"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Author: Kelly Chan\n",
      "Date: July 14 2014\n",
      "\n",
      "Project: Extracting attributes from the html contents by pages (Yelp)\n",
      "\n",
      "- url: http://www.yelp.com/search?find_loc=los+angeles&cflt=restaurants&start=%s\n",
      "- %s: the number of the pages\n",
      "\n",
      "steps:\n",
      "- 1. getting the html contents\n",
      "- 2. parsing attributes by regexes\n",
      "- 3. saving the data(.txt) to the local drive\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "import re\n",
      "import time\n",
      "import urllib2\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "def getHTML(url):\n",
      "    \"\"\" return html contents from the requested url \"\"\"\n",
      "\n",
      "    time.sleep(1.00)\n",
      "    html = urllib2.urlopen(url,timeout=10).read()\n",
      "    urllib2.urlopen(url).close()\n",
      "\n",
      "    soup = BeautifulSoup(html)\n",
      "\n",
      "    return soup\n",
      "\n",
      "\n",
      "def extractAttribute(content, pattern):\n",
      "    \"\"\" return the attribute that matching a specific pattern in the content \"\"\"\n",
      "    \n",
      "    return re.findall(re.compile(pattern), str(contents))\n",
      "\n",
      "def extract(soup, keyIndex):\n",
      "    \"\"\" extracting attributes from the html content \"\"\"\n",
      "\n",
      "    # getting the specific html content\n",
      "    content = soup.find('div', attrs={'data-key': keyIndex})\n",
      "\n",
      "    # index\n",
      "    pattern = r\"<span class=\\\"indexed-biz-name\\\">(\\d+)\"\n",
      "    index = extractAttribute(content, pattern)\n",
      "    #print index\n",
      "\n",
      "    # link\n",
      "    #pattern = r\"biz-name\\\".*(/biz/[\\w?%?+-?]+)\\\"\"\n",
      "    pattern = r\"biz-name\\\".*(/biz/.*)\\\"\" \n",
      "    link = extractAttribute(content, pattern)\n",
      "    #print link\n",
      "\n",
      "    # name\n",
      "    pattern = r\"biz-name.*>(.*)</a>\"\n",
      "    name = extractAttribute(content, pattern)\n",
      "    #print name\n",
      "\n",
      "    # rating\n",
      "    pattern = r\"star-img ([\\w+_?]+)\"\n",
      "    rating = extractAttribute(content, pattern)\n",
      "    #print rating\n",
      "\n",
      "    # review\n",
      "    pattern = r\"(\\d+) reviews\"\n",
      "    review = extractAttribute(content, pattern)\n",
      "    #print review\n",
      "\n",
      "    # price\n",
      "    pattern = r\"business-attribute price-range\\\">(.*)</span>\"\n",
      "    price = extractAttribute(content, pattern)\n",
      "    #print price\n",
      "\n",
      "    # category\n",
      "    pattern = r\"cflt=(\\w+)\"\n",
      "    category = extractAttribute(content, pattern)\n",
      "    #print category\n",
      "\n",
      "    # neighborhood\n",
      "    pattern = r\"neighborhood-str-list\\\">\\n\\s+(.*)\\s+</span>\"\n",
      "    neighborhood = extractAttribute(content, pattern)\n",
      "    #print neighborhood\n",
      "\n",
      "    # address\n",
      "    #pattern = r\"\\s+(.*)<br>\"\n",
      "    pattern = r\"<address>\\n([\\s\\S]*)</address>\"\n",
      "    address = extractAttribute(content, pattern)\n",
      "    #print address\n",
      "\n",
      "    # phones\n",
      "    #pattern = r\"(\\([\\d]+\\) [\\d]+-[\\d]+)\"\n",
      "    pattern = r\"biz-phone\\\">\\n\\s+(.*)\\n\\s+</span>\"\n",
      "    phone = extractAttribute(content, pattern)\n",
      "    #print phone\n",
      "\n",
      "    # feedback\n",
      "    pattern = r\"<p class=\\\"snippet\\\">(.*)</p>\"\n",
      "    feedback = extractAttribute(content, pattern)\n",
      "    #print feedback\n",
      "\n",
      "    return [index, link, name, \\\n",
      "            rating, review, price, category, \\\n",
      "            neighborhood, address, phone, feedback]\n",
      "\n",
      "\n",
      "def outTxt(data, outPath, fileName):\n",
      "    \"\"\" output the data as .txt file \"\"\"\n",
      "\n",
      "    with open(outPath+fileName, \"wb\") as f:\n",
      "        f.write(\"index,link,name,rating,review,price,category,neighborhood,address,phone,feedback\\n\")\n",
      "        for record in data:\n",
      "            f.write(\"%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s\\n\" % \\\n",
      "                    (record[0],record[1],record[2],record[3],record[4],record[5],record[6],\\\n",
      "                     record[7],record[8],record[9],record[10]))\n",
      "\n",
      "def getPagesData(url, pages):\n",
      "    \"\"\" extracting the data by pages and then return the full data \"\"\"\n",
      "\n",
      "    data = []\n",
      "    for page in range(pages):\n",
      "        #print \"page: \", page*10\n",
      "        pageURL = (url % str(page*10))  # setting the url of each page\n",
      "        #print \"pageURL: \", pageURL\n",
      "        soup = getHTML(pageURL)\n",
      "\n",
      "        subData = []\n",
      "        for dataKey in range(page*10+1, page*10+11):  # setting the number of the data-key for each page\n",
      "            #print \"dataKey: \", dataKey\n",
      "            record = extract(soup, str(dataKey))\n",
      "            subData.append(record)\n",
      "        data.extend(subData)\n",
      "\n",
      "    return data\n",
      "\n",
      "\n",
      "def main():\n",
      "\n",
      "    pages = 20\n",
      "    url = \"http://www.yelp.com/search?find_loc=los+angeles&cflt=restaurants&start=%s\"\n",
      "    outPath = \"path/regexEval/data/\"\n",
      "    fileName = \"raw_pages_data.txt\"\n",
      "\n",
      "\n",
      "    data = getPagesData(url, pages)\n",
      "    outTxt(data, outPath, fileName)\n",
      "\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2. Cleansing the data from the extracted attributes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Author: Kelly Chan\n",
      "Date: July 14 2014\n",
      "\n",
      "Project: Cleansing the data from the extracted attributes (by Pages)\n",
      "\n",
      "- url: http://www.yelp.com/search?find_loc=los+angeles&cflt=restaurants&start=%s\n",
      "- %s: the number of the pages\n",
      "\n",
      "steps:\n",
      "- 1. getting the data extracted from the html contents\n",
      "- 2. cleansing the data by attributes\n",
      "- 3. saving the cleaned data (.tsv) to the local drive\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "def getData(datafile):\n",
      "    \"\"\" reading the .txt data and then return it \"\"\"\n",
      "\n",
      "    data = []\n",
      "    with open(datafile, 'rb') as f:\n",
      "        for line in f.readlines():\n",
      "            thisLine = line.strip().split('],[')\n",
      "            data.append(thisLine)\n",
      "    return data\n",
      "\n",
      "def cleanLeftBracket(attribute):\n",
      "    \"\"\" cleansing the left bracket \"\"\"\n",
      "    \n",
      "    return attribute.replace(\"['\", \"\").replace(\"'\", \"\")\n",
      "\n",
      "def cleanRightBracket(attribute):\n",
      "    \"\"\" cleansing the right bracket \"\"\"\n",
      "    \n",
      "    return attribute.replace(\"]\", \"\")\n",
      "\n",
      "def cleanString(attribute):\n",
      "    \"\"\" cleansing the string \"\"\"\n",
      "    \n",
      "    return attribute.replace(\"'\", \"\")\n",
      "\n",
      "def cleanAttributes(data):\n",
      "    \"\"\" cleansing the attributes one by one and then return the cleaned data \"\"\"\n",
      "\n",
      "    cleanedData = []\n",
      "\n",
      "    for record in data[1:]:\n",
      "\n",
      "        # index\n",
      "        index = cleanLeftBracket(record[0]).strip()\n",
      "        #print index\n",
      "\n",
      "        # link\n",
      "        link = cleanString(record[1]).strip()\n",
      "        link = \"http://www.yelp.com/\" + link\n",
      "        #print link\n",
      "        \n",
      "        # name\n",
      "        name = cleanString(record[2]).strip()\n",
      "        #print name\n",
      "\n",
      "        # rating\n",
      "        rating = cleanString(record[3]).strip()\n",
      "        #print rating\n",
      "\n",
      "        # review\n",
      "        review = cleanString(record[4]).strip()\n",
      "        #print review\n",
      "\n",
      "        # price\n",
      "        price = cleanString(record[5]).strip()\n",
      "        #print price\n",
      "\n",
      "        # category\n",
      "        categories = cleanString(record[6]).strip()\n",
      "        #print categories\n",
      "\n",
      "        # neighborhood\n",
      "        neighborhood = cleanString(record[7]).strip()\n",
      "        #print neighborhood\n",
      "\n",
      "        # address\n",
      "        address = cleanString(record[8]).strip()\n",
      "        address = address.replace(\"\\\\n        </br>\", \"\")\n",
      "        address = address.replace(\"\\\\n\", \"\")\n",
      "        address = address.split('<br>')\n",
      "        if len(address) == 1:\n",
      "            road = \"\"\n",
      "            mainAddress = address[0]\n",
      "        elif len(address) == 2:\n",
      "            road = address[0].strip()\n",
      "            mainAddress = address[1]\n",
      "        #print road\n",
      " \n",
      "        mainAddress = mainAddress.split(\",\")\n",
      "        city = mainAddress[0].strip()\n",
      "        state, postCode = mainAddress[1].strip().split(\" \")\n",
      "        #print city\n",
      "        #print state, postCode\n",
      "\n",
      "        # phone\n",
      "        phone = cleanString(record[9]).strip()\n",
      "        #print phone\n",
      "\n",
      "        # feedback\n",
      "        feedback = cleanRightBracket(record[10]) \n",
      "        #print feedback\n",
      "\n",
      "        cleanedData.append([index, link, name, rating, review, price, categories, \\\n",
      "                     neighborhood, road, city, postCode, phone, feedback])\n",
      "\n",
      "    return cleanedData\n",
      "\n",
      "def outTSV(data, outPath, fileName):\n",
      "    \"\"\" output the data as .tsv file \"\"\"\n",
      "\n",
      "    header = \"index\\tlink\\tname\\trating\\treview\\tprice\\tcategories\\tneighborhood\\troad\\tcity\\tpostcode\\tphone\\tfeedback\\n\"\n",
      "\n",
      "    with open(outPath+fileName, \"wb\") as f:\n",
      "        f.write(header)\n",
      "        for record in data:\n",
      "            f.write(\"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n\" % \\\n",
      "                    (record[0],record[1],record[2],record[3],record[4],record[5],record[6],\\\n",
      "                     record[7],record[8],record[9],record[10],record[11],record[12]))\n",
      "\n",
      "\n",
      "def main():\n",
      "\n",
      "    dataPath = \"path/regexEval/data/\"\n",
      "    fileName = \"raw_pages_data.txt\"\n",
      "    outName = \"cleaned_pages_data.tsv\"\n",
      "\n",
      "    data = getData(dataPath+fileName)\n",
      "    cleanedData = cleanAttributes(data)\n",
      "    outTSV(cleanedData, dataPath, outName)\n",
      " \n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}